

# Данные

Для нужд вычислительных экспериментов были обработаны и объеденины представленные датасеты:

- Оригинальный датасет, представленный кейсодержатаелем (Tinkoff Internal)

- Blackmoon/russian-language-toxic-comments
- http://study.mokoron.com
- Датасет комментариев из социальной сети "Одноклассники".

-

Совокупный объем датасета равен 448001 комментариюю 

# Архитектура решения

![photo_2021-04-15_14-57-18](C:\Users\Eighonet Aerta\Downloads\photo_2021-04-15_14-57-18.jpg)

# Предобработка

- Замена на токены: [$TSLA] → акция, @user → пользователь;
- Spellchecker: DeepPavlov;
- Лемматизация;
- Удаление символов <.,!?*-...>;
- Удаление стоп-слов.

Извлеченные дополнительные признаки:

- Упоминания акций и пользователей
- Местоимения;
- Caps Lock;
- Длина сообщений;
- Грамотность.

Сражение с переобучением

1. GCN позволяет лучше работать с переобучением на отдельные объекты (даже без явного выделения самих объектов). В то же время, GCN выступает в качестве взвешивающего алгоритма для финальной модели.
2. TF-IDF также способствует снижению переобучения.
3. Кроме того, в текущей архитектуре возможна реализация DropEdge (аналог Dropout в графовых сетях) и использование стратегии co-teaching.

Также пробовали

- Другие классификаторы (RF, Boosting, простые нейронные сети);
- 4 архитектуры GCN;
- Поиск имён собственных.

Что можно сделать

- DropEdge
- Co-teaching
- Генерация данных
- Улучшение проверки грамотности